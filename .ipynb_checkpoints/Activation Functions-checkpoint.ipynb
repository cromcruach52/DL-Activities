{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2465d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Using cached tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (21.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Using cached ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.27.1)\n",
      "Collecting keras>=3.2.0\n",
      "  Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.4-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (61.2.0)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.12.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.37.1)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.8.0-py3-none-any.whl (241 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.3.4)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.66.1-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: markdown-it-py, tensorboard-data-server, rich, protobuf, optree, namex, ml-dtypes, h5py, grpcio, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.6.0\n",
      "    Uninstalling h5py-3.6.0:\n",
      "      Successfully uninstalled h5py-3.6.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-it-py-3.0.0 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 rich-13.8.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348c0041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274c640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\csse1028038\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18571e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd14a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "# load the cifar-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images/255.0, test_images/255.0\n",
    "\n",
    "# class names for cifar-10\n",
    "class_names = {'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'ship', 'horse', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "602292d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function): \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=activation_function, input_shape=(32, 32, 3)))# The Conv2D layers are used for convolution operations with 32 and 64 filters.\n",
    "    model.add(layers.MaxPooling2D((2, 2)))#The MaxPooling2D layers downsample the feature maps.\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=activation_function)) \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=activation_function)) \n",
    "    \n",
    "    model.add(layers.Flatten()) # the flatten layer converts the 2d feature maps into a 1d vector\n",
    "    model.add(layers.Dense(64, activation=activation_function)) \n",
    "    model.add(layers.Dense(10))# output layer for 10 classes\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4bc391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, optimizer, epochs=3):\n",
    "  model.compile(optimizer = optimizer,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  history = model.fit(train_images, train_labels, epochs=epochs,\n",
    "                      validation_data =(test_images, test_labels))\n",
    "  \n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05aa3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with relu activation and adam optimizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSSE1028038\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.3416 - loss: 1.7793 - val_accuracy: 0.5307 - val_loss: 1.3066\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5653 - loss: 1.2355 - val_accuracy: 0.6000 - val_loss: 1.1182\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6202 - loss: 1.0737 - val_accuracy: 0.6344 - val_loss: 1.0265\n",
      "Training with relu activation and sgd optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1860 - loss: 2.1841 - val_accuracy: 0.3706 - val_loss: 1.7530\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3832 - loss: 1.7014 - val_accuracy: 0.4319 - val_loss: 1.5722\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4533 - loss: 1.5043 - val_accuracy: 0.4773 - val_loss: 1.4337\n",
      "Training with relu activation and rmsprop optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3500 - loss: 1.7691 - val_accuracy: 0.5623 - val_loss: 1.2220\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 1.1610 - val_accuracy: 0.6028 - val_loss: 1.1416\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6635 - loss: 0.9621 - val_accuracy: 0.6785 - val_loss: 0.9218\n",
      "Training with sigmoid activation and adam optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1805 - loss: 2.1771 - val_accuracy: 0.3653 - val_loss: 1.7631\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3805 - loss: 1.7058 - val_accuracy: 0.4199 - val_loss: 1.5894\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4403 - loss: 1.5448 - val_accuracy: 0.4568 - val_loss: 1.5155\n",
      "Training with sigmoid activation and sgd optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3099 - val_accuracy: 0.1000 - val_loss: 2.3050\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1036 - loss: 2.3050 - val_accuracy: 0.1000 - val_loss: 2.3048\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1020 - loss: 2.3050 - val_accuracy: 0.1000 - val_loss: 2.3037\n",
      "Training with sigmoid activation and rmsprop optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0997 - loss: 2.3155 - val_accuracy: 0.1000 - val_loss: 2.3079\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1042 - loss: 2.3071 - val_accuracy: 0.1026 - val_loss: 2.2996\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1994 - loss: 2.1446 - val_accuracy: 0.3168 - val_loss: 1.8855\n",
      "Training with tanh activation and adam optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4137 - loss: 1.6238 - val_accuracy: 0.5710 - val_loss: 1.2068\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5923 - loss: 1.1636 - val_accuracy: 0.6097 - val_loss: 1.1224\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6393 - loss: 1.0300 - val_accuracy: 0.6106 - val_loss: 1.1151\n",
      "Training with tanh activation and sgd optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2711 - loss: 2.0193 - val_accuracy: 0.4273 - val_loss: 1.6205\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4378 - loss: 1.5769 - val_accuracy: 0.4899 - val_loss: 1.4323\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4991 - loss: 1.4186 - val_accuracy: 0.5180 - val_loss: 1.3671\n",
      "Training with tanh activation and rmsprop optimizer...\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4088 - loss: 1.6598 - val_accuracy: 0.5434 - val_loss: 1.3020\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5906 - loss: 1.1631 - val_accuracy: 0.5451 - val_loss: 1.2902\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6404 - loss: 1.0369 - val_accuracy: 0.6265 - val_loss: 1.0942\n"
     ]
    }
   ],
   "source": [
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "optimizers = [\"adam\",\"sgd\",'rmsprop'] \n",
    "\n",
    "results = {}\n",
    "\n",
    "for activation in activation_functions:\n",
    "  for optimizer in optimizers:\n",
    "    print(f\"Training with {activation} activation and {optimizer} optimizer...\")\n",
    "    model = create_model(activation)\n",
    "    history = compile_and_train(model, optimizer, epochs = 3)\n",
    "    results[(activation, optimizer)] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b306ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    for key, history in results.items():\n",
    "        plt.plot(history.history[val_accuracy], label=f'{key[0] + key[1]}')\n",
    "        \n",
    "        plt.title('Validation Accuracy for Different Activation Functions and Optimizers')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    plot_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
